<!DOCTYPE html>
<html>
  <head>
    <title>Adaptive Multi-View Path Tracing</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="data/style.css" />
  </head>
  <body>
    <div class="main">
      <h1>Adaptive Multi-View Path Tracing</h1>

      <h2 style="text-align:center">
        <a style="text-decoration: none; color: #516482; margin: 15px;" target="_blank" href="https://bfraboni.github.io">
          Basile Fraboni 
        </a>
        
        <a style="text-decoration: none; color: #516482; margin: 15px; "target="_blank" href="http://perso.univ-lyon1.fr/jean-claude.iehl/">
          Jean-Claude Iehl 
        </a>
        
        <a style="text-decoration: none; color: #516482; margin: 15px; "target="_blank" href="https://perso.liris.cnrs.fr/vincent.nivoliers/">
          Vincent Nivoliers 
        </a>
        
        <a style="text-decoration: none; color: #516482; margin: 15px; "target="_blank" href="https://github.com/guibou?tab=followers">
          Guillaume Bouchard
        </a>
      </h2>

      <div style="text-align:center">
        <a style="text-decoration: none" target="_blank" href="paper.pdf">
          <img class="thumbnail" src="paper-thumbnail.png" alt="paper">
        </a>

        <a style="text-decoration: none" target="_blank" href="slides.pdf">
          <img class="thumbnail" src="slides-thumbnail.png" alt="slides">
        </a>

        <a style="text-decoration: none" target="_blank" href="https://github.com/bfraboni/smallmvpt">
          <img class="thumbnail" src="code-thumbnail.png" alt="code">
        </a>
      </div>

      <h2>Abstract</h2>

      <p>
        Rendering photo-realistic image sequences using path tracing and Monte Carlo integration often requires sampling a large
        number of paths to get converged results. In the context of rendering multiple views or animated sequences, such sampling can
        be highly redundant. Several methods have been developed to share sampled paths between spatially or temporarily similar
        views. However, such sharing is challenging since it can lead to bias in the final images. Our contribution is a Monte Carlo
        sampling technique which generates paths, taking into account several cameras. First, we sample the scene from all the cameras
        to generate hit points. Then, an importance sampling technique generates bouncing directions which are shared by a subset of
        cameras. This set of hit points and bouncing directions is then used within a regular path tracing solution. For animated scenes,
        paths remain valid for a fixed time only, but sharing can still occur between cameras as long as their exposure time intervals
        overlap. We show that our technique generates less noise than regular path tracing and does not introduce noticeable bias.
      </p>

      <h2>Cite</h2>
      <pre>
        <code>
        @inproceedings{fraboni:hal-02279950,
            TITLE = {{Adaptive multi-view path tracing}},
            AUTHOR = {Fraboni, Basile and Iehl, Jean-Claude and Nivoliers, Vincent and Bouchard, Guillaume},
            URL = {https://hal.archives-ouvertes.fr/hal-02279950},
            BOOKTITLE = {{EGSR 2019  Eurographics Symposium on Rendering}},
            ADDRESS = {Strasbourg, France},
            ORGANIZATION = {{Tamy Boubekeur and Pradeep Sen}},
            YEAR = {2019},
            KEYWORDS = {Computer graphics ; Ray tracing ; Visibility},
            PDF = {https://hal.archives-ouvertes.fr/hal-02279950/file/paper.pdf},
            HAL_ID = {hal-02279950},
            HAL_VERSION = {v1},
        }
        </code>
      </pre>
      
      <h2>Animated sequence #1</h2>

      <p>
        The following sequence is made of 100 frames. The sequence is a shot extracted from the Blender open movie Agent 327 made freely available by the Blender Institute. The standard method renders each frame independently. Our methods jointly renders all the frames, and shares paths between frames with overlapping exposure intervals. Our algorithm both reduces the variance and the perceived flickering for the same computation budget.
      </p>

      <h3>Total time budget 4000 seconds (40 seconds / frame)</h3>
      <div class="compare">
        <video 
          class="compared compared-vertical" 
          data-compare-top="standard"
          data-compare-bottom="ours"
          loop muted
          >
          <!-- <source src="barber.webm" type="video/webm"> -->
          <source src="data/barber-4000.mp4" type="video/mp4">
          <p>Your browser doesn't support HTML5 video. Here is a <a href="barber.mp4">link to the video</a> instead.</p>
        </video>
      </div>
    
      <h2>Animated sequence #2</h2>

      <p>
        The following sequence shows 100 frames of a custom Cornell Box, with fast moving cubes and glossy materials. This sequence is complex to render since cameras may see tangent geometry while cubes are moving, which implies large variations of the Jacobian and temporal visibility changes. The flickering reduction is particularly visible on the ceiling.
      </p>

      <div class="compare">
        <video 
          class="compared compared-vertical" 
          data-compare-top="standard"
          data-compare-bottom="ours"
          loop muted
          >
          <!-- <source src="barber.webm" type="video/webm"> -->
          <source src="data/cornell.mp4" type="video/mp4">
          <p>Your browser doesn't support HTML5 video. Here is a <a href="cornell.mp4">link to the video</a> instead.</p>
        </video>
      </div>

      <h2>Single shot</h2>

      <p>
        A single frame extracted from the barber shop sequence (4000 seconds).
      </p>

      <div class="compare">
        <img class="compared compared-left" data-compare="standard" src="data/single-038-time-004000.png"/>
        <img class="compared compared-right" data-compare="ours" src="data/multi-038-time-004000.png"/>
      </div>

      <h2>Examples rendered with SmallMVPT</h2>

      <p>
        Comparison on a 9 images sequence (scene 4 exp 4).
      </p>

      <div class="compare">
        <img class="compared compared-left" data-compare="standard 150s" src="data/smallmvpt/s4_noreuse.bmp"/>
        <img class="compared compared-right" data-compare="ours 150s" src="data/smallmvpt/s4_reuse.bmp"/>
      </div>

      <p>
        Comparison on a 9 images sequence (scene 0).
      </p>

      <div class="compare">
        <img class="compared compared-left" data-compare="standard 80s" src="data/smallmvpt/s0_noreuse.bmp"/>
        <img class="compared compared-right" data-compare="ours 80s" src="data/smallmvpt/s0_reuse.bmp"/>
      </div>

    </div>
    <script type="text/javascript" src="data/compare.js"></script>
  </body>
</html>
